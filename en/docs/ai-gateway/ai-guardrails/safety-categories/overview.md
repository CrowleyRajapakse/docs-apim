# Key Safety Categories Covered by WSO2 AI Guardrails

[![AI Gateway]({{base_path}}/assets/img/learn/ai-gateway/ai-guardrail-safety-categories.png){: style="width:40%"}]({{base_path}}/assets/img/learn/ai-gateway/ai-guardrail-safety-categories.png)

WSO2 AI Guardrails comprehensively address critical safety aspects across four foundational categories, ensuring secure, compliant, and reliable AI interactions:

| Category                  | Description                                                                                   |
|---------------------------|-----------------------------------------------------------------------------------------------|
| [**Content Safety**](../safety-categories/content-safety.md)       | Detects and filters toxic, harmful, or offensive content to ensure safe and appropriate AI outputs.             |
| [**Content Usage Control**](../safety-categories/content-usage-control.md) | Implements organizational policies by enforcing word, sentences, and content usage guidelines consistently.    |

Explore the comprehensive guardrail capabilities offered within each safety category.
